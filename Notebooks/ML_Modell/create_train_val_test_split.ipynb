{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the data on the disk into a train, validation and test set"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Create for each tile on folder which contains the folder from every season for this tile\n",
    "2. Random sample tiles for the train, validation and test set\n",
    "3. Copy the tiles from the disk to the train, validation and test folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import rasterio\n",
    "import re\n",
    "import os\n",
    "import random\n",
    "import shutil\n",
    "import torch\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "IDENTIFIER_REGEX = re.compile(\n",
    "    r\"\"\"(?P<mission>S2[A-B])_MSI\n",
    "        (?P<product_level>L[1-2][A-C])_\n",
    "        (?P<sensing_time>\\d{8}T\\d{6})_\n",
    "        (?P<processing_baseline>N\\d{4})_\n",
    "        (?P<relative_orbit>R\\d{3})_T\n",
    "        (?P<utm_code>\\d{2})\n",
    "        (?P<latitude_band>\\w{1})\n",
    "        (?P<square>\\w{2})_\n",
    "        (?P<year>\\d{4})\n",
    "        (?P<month>\\d{2})\n",
    "        (?P<day>\\d{2})T\n",
    "        (?P<product_time>\\d{6})\"\"\",\n",
    "    re.VERBOSE,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tile_and_date(identifier: str):\n",
    "    regex_match = re.search(IDENTIFIER_REGEX, identifier)\n",
    "\n",
    "    if not regex_match:\n",
    "        return None, None\n",
    "\n",
    "    utm_code = regex_match.group(\"utm_code\")\n",
    "    latitude_band = regex_match.group(\"latitude_band\")\n",
    "    square = regex_match.group(\"square\")\n",
    "    year = regex_match.group(\"year\")\n",
    "    # remove leading zeros\n",
    "    month = str(int(regex_match.group(\"month\")))\n",
    "    day = str(int(regex_match.group(\"day\")))\n",
    "\n",
    "    tile = f\"{utm_code}{latitude_band}{square}\"\n",
    "    tile_date = f\"{year}-{month}-{day}\"\n",
    "\n",
    "    return tile, tile_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_prepro_path = Path(r'C:\\Users\\Fabian\\Documents\\Github_Masterthesis\\Solarpark-detection\\data_local\\images_only_AOI_test_color_corr_cleaned')\n",
    "masks_prepro_path = Path(r'C:\\Users\\Fabian\\Documents\\Github_Masterthesis\\Solarpark-detection\\data_local\\masks_only_AOI_test_color_corr_cleaned')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a list of all tiles which are available on the disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def index_to_filename(image_dir: Path, set_list: list) -> list:\n",
    "    set_filenames = []\n",
    "    for file_path in image_dir.glob(\"*.pt\"):\n",
    "        tile, number, date = file_path.stem.split(\"_\")\n",
    "        if (tile, number) in set_list:\n",
    "            set_filenames.append(str(file_path))  # .name\n",
    "    return set_filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a list of all tiles\n",
    "tile_list = []\n",
    "for file_path in images_prepro_path.glob(\"*.pt\"):\n",
    "    filename = file_path.stem\n",
    "    tile, number, date = filename.split(\"_\")\n",
    "    tile_list.append(tile)\n",
    "\n",
    "# set is used to get unique values of tiles\n",
    "tiles_unique = list(set(tile_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select random tiles for train, val and test\n",
    "random.seed(42)\n",
    "random.shuffle(tiles_unique)\n",
    "\n",
    "num_total = len(tiles_unique)\n",
    "num_train = int(num_total * 0.7)\n",
    "num_val = int(num_total * 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create train, val and test list\n",
    "train_list = tiles_unique[:num_train]\n",
    "val_list = tiles_unique[num_train : num_train + num_val]\n",
    "test_list = tiles_unique[num_train + num_val :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a directory for each set\n",
    "train_dir = Path(r'C:\\Users\\Fabian\\Documents\\Github_Masterthesis\\Solarpark-detection\\data_local\\data_splitted')\n",
    "for set_name in [\"train\", \"val\", \"test\"]:\n",
    "    os.makedirs(train_dir / set_name, exist_ok=True)\n",
    "    os.makedirs(train_dir / set_name / \"images\", exist_ok=True)\n",
    "    os.makedirs(train_dir / set_name / \"masks\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in images_prepro_path.glob(\"*.pt\"):\n",
    "    file_stammed = file.stem\n",
    "    filename = file.name\n",
    "    tile, _, _ = file_stammed.split(\"_\")\n",
    "    if tile in train_list:\n",
    "        shutil.copyfile(images_prepro_path / filename, train_dir / \"train\" / \"images\" / filename)\n",
    "        shutil.copyfile(masks_prepro_path / filename, train_dir / \"train\" / \"masks\" / filename)\n",
    "    elif tile in val_list:\n",
    "        shutil.copyfile(images_prepro_path / filename, train_dir / \"val\" / \"images\" / filename)\n",
    "        shutil.copyfile(masks_prepro_path / filename, train_dir / \"val\" / \"masks\" / filename)\n",
    "    elif tile in test_list:\n",
    "        shutil.copyfile(images_prepro_path / filename, train_dir / \"test\" / \"images\" / filename)\n",
    "        shutil.copyfile(masks_prepro_path / filename, train_dir / \"test\" / \"masks\" / filename)\n",
    "    else:\n",
    "        print(\"Error: Tile not in any set!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of files in each set:\n",
      "Train images: 3832\n",
      "Train masks: 3832\n",
      "Val images: 489\n",
      "Val masks: 489\n",
      "Test images: 342\n",
      "Test masks: 342\n"
     ]
    }
   ],
   "source": [
    "# check if all files are copied\n",
    "print(\"Number of files in each set:\")\n",
    "print(f'Train images: {len(list(train_dir.glob(\"train/images/*.pt\")))}')\n",
    "print(f'Train masks: {len(list(train_dir.glob(\"train/masks/*.pt\")))}')\n",
    "print(f'Val images: {len(list(train_dir.glob(\"val/images/*.pt\")))}')\n",
    "print(f'Val masks: {len(list(train_dir.glob(\"val/masks/*.pt\")))}')\n",
    "print(f'Test images: {len(list(train_dir.glob(\"test/images/*.pt\")))}')\n",
    "print(f'Test masks: {len(list(train_dir.glob(\"test/masks/*.pt\")))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Sum of all files:\")\n",
    "print(f'Images: {len(list(train_dir.glob(\"**/*.pt\")))}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Same as before, but now with the undersampled data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Additionally the data needs to be transformed from .tiff to tensor (.pt) format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_prepro_path = Path(r'C:\\Users\\Fabian\\Documents\\Github_Masterthesis\\Solarpark-detection\\data_local\\images_undersampling')\n",
    "masks_prepro_path = Path(r'C:\\Users\\Fabian\\Documents\\Github_Masterthesis\\Solarpark-detection\\data_local\\masks_undersampling')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a list of all tiles\n",
    "tile_list = []\n",
    "for file_path in images_prepro_path.glob(\"*.tif\"):\n",
    "    filename = file_path.stem\n",
    "    tile, number, date = filename.split(\"_\")\n",
    "    tile_list.append(tile)\n",
    "\n",
    "# set is used to get unique values of tiles\n",
    "tiles_unique = list(set(tile_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tiles: 56\n"
     ]
    }
   ],
   "source": [
    "print(f'Number of tiles: {len(tiles_unique)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select random tiles for train, val and test\n",
    "random.seed(42)\n",
    "random.shuffle(tiles_unique)\n",
    "\n",
    "num_total = len(tiles_unique)\n",
    "num_train = int(num_total * 0.7)\n",
    "num_val = int(num_total * 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create train, val and test list\n",
    "train_list = tiles_unique[:num_train]\n",
    "val_list = tiles_unique[num_train : num_train + num_val]\n",
    "test_list = tiles_unique[num_train + num_val :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tiles in each set:\n",
      "Train: 39\n",
      "Val: 11\n",
      "Test: 6\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of tiles in each set:\")\n",
    "print(f'Train: {len(train_list)}')\n",
    "print(f'Val: {len(val_list)}')\n",
    "print(f'Test: {len(test_list)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a directory for each set\n",
    "data_dir = Path(r'C:\\Users\\Fabian\\Documents\\Github_Masterthesis\\Solarpark-detection\\data_local\\data_splitted_undersampling')\n",
    "for set_name in [\"train\", \"val\", \"test\"]:\n",
    "    os.makedirs(data_dir / set_name, exist_ok=True)\n",
    "    os.makedirs(data_dir / set_name / \"images\", exist_ok=True)\n",
    "    os.makedirs(data_dir / set_name / \"masks\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/20683 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20683/20683 [09:50<00:00, 35.03it/s]\n"
     ]
    }
   ],
   "source": [
    "num_files = len(list(images_prepro_path.glob(\"*.tif\")))\n",
    "for file in tqdm(images_prepro_path.glob(\"*.tif\"), total=num_files):\n",
    "    file_stammed = file.stem\n",
    "    filename = file.name\n",
    "    tile, _, _ = file_stammed.split(\"_\")\n",
    "\n",
    "    image_path = images_prepro_path / filename\n",
    "    mask_path = masks_prepro_path / filename\n",
    "    \n",
    "    image = rasterio.open(image_path).read()\n",
    "    mask = rasterio.open(mask_path).read()\n",
    "    \n",
    "    image_tensor = torch.from_numpy(image)\n",
    "    mask_tensor = torch.from_numpy(mask)\n",
    "\n",
    "    if tile in train_list:\n",
    "        torch.save(image_tensor, data_dir / \"train\" / \"images\" / f\"{file_stammed}.pt\")\n",
    "        torch.save(mask_tensor, data_dir / \"train\" / \"masks\" / f\"{file_stammed}.pt\")\n",
    "    elif tile in val_list:\n",
    "        torch.save(image_tensor, data_dir / \"val\" / \"images\" / f\"{file_stammed}.pt\")\n",
    "        torch.save(mask_tensor, data_dir / \"val\" / \"masks\" / f\"{file_stammed}.pt\")\n",
    "    elif tile in test_list:\n",
    "        torch.save(image_tensor, data_dir / \"test\" / \"images\" / f\"{file_stammed}.pt\")\n",
    "        torch.save(mask_tensor, data_dir / \"test\" / \"masks\" / f\"{file_stammed}.pt\")\n",
    "    else:\n",
    "        print(\"Error: Tile not in any set!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of files in each set:\n",
      "Train images: 14178\n",
      "Train masks: 14178\n",
      "Val images: 4648\n",
      "Val masks: 4648\n",
      "Test images: 1857\n",
      "Test masks: 1857\n"
     ]
    }
   ],
   "source": [
    "# check if all files are copied\n",
    "print(\"Number of files in each set:\")\n",
    "print(f'Train images: {len(list(data_dir.glob(\"train/images/*.pt\")))}')\n",
    "print(f'Train masks: {len(list(data_dir.glob(\"train/masks/*.pt\")))}')\n",
    "print(f'Val images: {len(list(data_dir.glob(\"val/images/*.pt\")))}')\n",
    "print(f'Val masks: {len(list(data_dir.glob(\"val/masks/*.pt\")))}')\n",
    "print(f'Test images: {len(list(data_dir.glob(\"test/images/*.pt\")))}')\n",
    "print(f'Test masks: {len(list(data_dir.glob(\"test/masks/*.pt\")))}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create geojson file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import rasterio.features\n",
    "import numpy as np\n",
    "from typing import Tuple, List\n",
    "from shapely.geometry import Polygon\n",
    "from rasterio.warp import transform_geom\n",
    "from datetime import datetime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>avg_confidence</th>\n",
       "      <th>comment</th>\n",
       "      <th>date_of_data</th>\n",
       "      <th>first_detection</th>\n",
       "      <th>is_valid</th>\n",
       "      <th>last_detection</th>\n",
       "      <th>name_in_aws</th>\n",
       "      <th>name_of_model</th>\n",
       "      <th>peak_power</th>\n",
       "      <th>size_in_sq_m</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>None</td>\n",
       "      <td>2023-05-09</td>\n",
       "      <td>2023-05-09</td>\n",
       "      <td>non-valid</td>\n",
       "      <td>2023-05-09</td>\n",
       "      <td>32UPC_20_2023-5-9.tif</td>\n",
       "      <td>solar-park-detection</td>\n",
       "      <td>3.088</td>\n",
       "      <td>19300.0</td>\n",
       "      <td>POLYGON ((11.20714 52.31969, 11.20787 52.31968...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>None</td>\n",
       "      <td>2023-05-09</td>\n",
       "      <td>2023-05-09</td>\n",
       "      <td>non-valid</td>\n",
       "      <td>2023-05-09</td>\n",
       "      <td>32UPC_20_2023-5-9.tif</td>\n",
       "      <td>solar-park-detection</td>\n",
       "      <td>4.512</td>\n",
       "      <td>28200.0</td>\n",
       "      <td>POLYGON ((11.20472 52.31821, 11.20530 52.31820...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>None</td>\n",
       "      <td>2023-05-09</td>\n",
       "      <td>2023-05-09</td>\n",
       "      <td>valid</td>\n",
       "      <td>2023-05-09</td>\n",
       "      <td>32UPC_31_2023-5-9.tif</td>\n",
       "      <td>solar-park-detection</td>\n",
       "      <td>2.384</td>\n",
       "      <td>14900.0</td>\n",
       "      <td>POLYGON ((11.61811 52.32361, 11.61870 52.32360...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>None</td>\n",
       "      <td>2023-05-09</td>\n",
       "      <td>2023-05-09</td>\n",
       "      <td>valid</td>\n",
       "      <td>2023-05-09</td>\n",
       "      <td>32UPC_33_2023-5-9.tif</td>\n",
       "      <td>solar-park-detection</td>\n",
       "      <td>4.672</td>\n",
       "      <td>29200.0</td>\n",
       "      <td>POLYGON ((11.68509 52.30520, 11.68568 52.30519...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>None</td>\n",
       "      <td>2023-05-09</td>\n",
       "      <td>2023-05-09</td>\n",
       "      <td>non-valid</td>\n",
       "      <td>2023-05-09</td>\n",
       "      <td>32UPC_193_2023-5-9.tif</td>\n",
       "      <td>solar-park-detection</td>\n",
       "      <td>1.408</td>\n",
       "      <td>8800.0</td>\n",
       "      <td>POLYGON ((11.09063 52.23873, 11.09060 52.23810...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   avg_confidence comment date_of_data first_detection   is_valid   \n",
       "0             0.0    None   2023-05-09      2023-05-09  non-valid  \\\n",
       "1             0.0    None   2023-05-09      2023-05-09  non-valid   \n",
       "2             0.0    None   2023-05-09      2023-05-09      valid   \n",
       "3             0.0    None   2023-05-09      2023-05-09      valid   \n",
       "4             0.0    None   2023-05-09      2023-05-09  non-valid   \n",
       "\n",
       "  last_detection             name_in_aws         name_of_model  peak_power   \n",
       "0     2023-05-09   32UPC_20_2023-5-9.tif  solar-park-detection       3.088  \\\n",
       "1     2023-05-09   32UPC_20_2023-5-9.tif  solar-park-detection       4.512   \n",
       "2     2023-05-09   32UPC_31_2023-5-9.tif  solar-park-detection       2.384   \n",
       "3     2023-05-09   32UPC_33_2023-5-9.tif  solar-park-detection       4.672   \n",
       "4     2023-05-09  32UPC_193_2023-5-9.tif  solar-park-detection       1.408   \n",
       "\n",
       "   size_in_sq_m                                           geometry  \n",
       "0       19300.0  POLYGON ((11.20714 52.31969, 11.20787 52.31968...  \n",
       "1       28200.0  POLYGON ((11.20472 52.31821, 11.20530 52.31820...  \n",
       "2       14900.0  POLYGON ((11.61811 52.32361, 11.61870 52.32360...  \n",
       "3       29200.0  POLYGON ((11.68509 52.30520, 11.68568 52.30519...  \n",
       "4        8800.0  POLYGON ((11.09063 52.23873, 11.09060 52.23810...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# strucutre of geojson\n",
    "gdf = gpd.read_file(r'C:\\Users\\Fabian\\Documents\\Github_Masterthesis\\Solarpark-detection\\data_local\\geojsons\\solar-parks.geojson')\n",
    "gdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = Path(r'C:\\Users\\Fabian\\Documents\\Github_Masterthesis\\Solarpark-detection\\data_local\\data_splitted_undersampling')\n",
    "mask_dir = Path(r'C:\\Users\\Fabian\\Documents\\Github_Masterthesis\\Solarpark-detection\\data_local\\masks_undersampling')\n",
    "file_list = data_dir.glob(\"test/masks/*.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def masks_to_polygons(\n",
    "    masks: np.ndarray, metadata: dict\n",
    ") -> Tuple[List[Polygon], List[float]]:\n",
    "    masks = masks.astype(np.uint8)\n",
    "    transform = metadata[\"transform\"]\n",
    "    crs = metadata[\"crs\"]\n",
    "    # extract shapes\n",
    "    shapes = rasterio.features.shapes(masks, transform=transform)\n",
    "    polygons = []\n",
    "    areas = []\n",
    "    peak_powers = []\n",
    "    for shape in shapes:\n",
    "        if shape[1] == 1:\n",
    "            polygon = Polygon(shape[0][\"coordinates\"][0])\n",
    "            area = polygon.area\n",
    "            # realistically, the smallest solar park should be bigger than 10.000 m²\n",
    "            if area >= 0:\n",
    "                # Transform the polygon coordinates to EPSG:4326\n",
    "                transformed_geom = transform_geom(\n",
    "                    crs, \"EPSG:4326\", polygon.__geo_interface__\n",
    "                )\n",
    "                transformed_coords = transformed_geom[\"coordinates\"][0]\n",
    "                transformed_polygon = Polygon(transformed_coords)\n",
    "                peak_power = calc_peak_power(area_in_sq_m=area)\n",
    "                polygons.append(transformed_polygon)\n",
    "                areas.append(area)\n",
    "                peak_powers.append(peak_power)\n",
    "    return polygons, areas, peak_powers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_peak_power(area_in_sq_m: float) -> float:\n",
    "    # https://www.bundesnetzagentur.de/SharedDocs/Downloads/DE/Sachgebiete/Energie/Unternehmen_Institutionen/ErneuerbareEnergien/PV-Freiflaechenanlagen/Bericht_Flaecheninanspruchnahme_2016.pdf?__blob=publicationFile&v=2#:~:text=Die%20bereits%20im%20Rahmen%20der,Ackerland%20in%20benachteiligten%20Gebieten%20errichtet. # noqa\n",
    "    # page 8 on the pdf (german)\n",
    "    # 1,6 acre = 1 MWp\n",
    "    # area in sq m / 10000 = area in acr * 1.6 = peak power in MWp\n",
    "    return area_in_sq_m / 10000 * 1.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "polygons_list = []\n",
    "areas_list = []\n",
    "peak_powers_list = []\n",
    "filenames_list = []\n",
    "for file_path in file_list:\n",
    "    filename = file_path.stem\n",
    "    mask = rasterio.open(mask_dir / f\"{filename}.tif\").read()\n",
    "    metadata   = rasterio.open(mask_dir / f\"{filename}.tif\").meta\n",
    "    if mask.sum() > 0:\n",
    "        polygons, areas, peak_powers = masks_to_polygons(mask, metadata)\n",
    "        polygons_list.extend(polygons)\n",
    "        areas_list.extend(areas)\n",
    "        peak_powers_list.extend(peak_powers)\n",
    "        for i in range(len(polygons)):\n",
    "            filenames_list.append(f\"{filename}.tif\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['avg_confidence', 'comment', 'date_of_data', 'first_detection',\n",
       "       'is_valid', 'last_detection', 'name_in_aws', 'name_of_model',\n",
       "       'peak_power', 'size_in_sq_m', 'geometry'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gdf.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_string = \"2018-01-01\"\n",
    "date_obj = datetime.strptime(date_string, \"%Y-%m-%d\").date()\n",
    "data = {\n",
    "    \"name_of_model\": \"test\",\n",
    "    \"size_in_sq_m\": areas_list,\n",
    "    \"peak_power\": peak_powers_list,\n",
    "    \"date_of_data\": '2018-01-01',\n",
    "    \"first_detection\": '2018-01-01',  # will be handled on api level\n",
    "    \"last_detection\": '2018-01-01',  # will be handled on api level\n",
    "    \"avg_confidence\": 0,\n",
    "    \"name_in_aws\": filenames_list,\n",
    "    \"is_valid\": \"None\",\n",
    "    \"comment\": \"test\",\n",
    "    \"geometry\": polygons_list\n",
    "}\n",
    "df = gpd.GeoDataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name_of_model</th>\n",
       "      <th>size_in_sq_m</th>\n",
       "      <th>peak_power</th>\n",
       "      <th>date_of_data</th>\n",
       "      <th>first_detection</th>\n",
       "      <th>last_detection</th>\n",
       "      <th>avg_confidence</th>\n",
       "      <th>name_in_aws</th>\n",
       "      <th>is_valid</th>\n",
       "      <th>comment</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>test</td>\n",
       "      <td>29200.0</td>\n",
       "      <td>4.672</td>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>0</td>\n",
       "      <td>32UMA_1034_2018-11-16.tif</td>\n",
       "      <td>None</td>\n",
       "      <td>test</td>\n",
       "      <td>POLYGON ((8.38072 50.02334, 8.38617 50.02337, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>test</td>\n",
       "      <td>29200.0</td>\n",
       "      <td>4.672</td>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>0</td>\n",
       "      <td>32UMA_1034_2018-4-20.tif</td>\n",
       "      <td>None</td>\n",
       "      <td>test</td>\n",
       "      <td>POLYGON ((8.38072 50.02334, 8.38617 50.02337, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>test</td>\n",
       "      <td>29200.0</td>\n",
       "      <td>4.672</td>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>0</td>\n",
       "      <td>32UMA_1034_2018-9-27.tif</td>\n",
       "      <td>None</td>\n",
       "      <td>test</td>\n",
       "      <td>POLYGON ((8.38072 50.02334, 8.38617 50.02337, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>test</td>\n",
       "      <td>38700.0</td>\n",
       "      <td>6.192</td>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>0</td>\n",
       "      <td>32UMA_1042_2018-11-16.tif</td>\n",
       "      <td>None</td>\n",
       "      <td>test</td>\n",
       "      <td>POLYGON ((8.64275 50.02427, 8.64303 50.02427, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>test</td>\n",
       "      <td>97900.0</td>\n",
       "      <td>15.664</td>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>0</td>\n",
       "      <td>32UMA_1042_2018-11-16.tif</td>\n",
       "      <td>None</td>\n",
       "      <td>test</td>\n",
       "      <td>POLYGON ((8.63968 50.02444, 8.64163 50.02444, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>625</th>\n",
       "      <td>test</td>\n",
       "      <td>41600.0</td>\n",
       "      <td>6.656</td>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>0</td>\n",
       "      <td>32UPF_1622_2018-4-20.tif</td>\n",
       "      <td>None</td>\n",
       "      <td>test</td>\n",
       "      <td>POLYGON ((12.01673 54.17422, 12.01780 54.17419...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>626</th>\n",
       "      <td>test</td>\n",
       "      <td>41600.0</td>\n",
       "      <td>6.656</td>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>0</td>\n",
       "      <td>32UPF_1622_2018-7-6.tif</td>\n",
       "      <td>None</td>\n",
       "      <td>test</td>\n",
       "      <td>POLYGON ((12.01673 54.17422, 12.01780 54.17419...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>627</th>\n",
       "      <td>test</td>\n",
       "      <td>83400.0</td>\n",
       "      <td>13.344</td>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>0</td>\n",
       "      <td>32UPF_1623_2018-10-14.tif</td>\n",
       "      <td>None</td>\n",
       "      <td>test</td>\n",
       "      <td>POLYGON ((12.01887 54.17417, 12.01869 54.17165...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>628</th>\n",
       "      <td>test</td>\n",
       "      <td>83400.0</td>\n",
       "      <td>13.344</td>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>0</td>\n",
       "      <td>32UPF_1623_2018-4-20.tif</td>\n",
       "      <td>None</td>\n",
       "      <td>test</td>\n",
       "      <td>POLYGON ((12.01887 54.17417, 12.01869 54.17165...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>629</th>\n",
       "      <td>test</td>\n",
       "      <td>83400.0</td>\n",
       "      <td>13.344</td>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>0</td>\n",
       "      <td>32UPF_1623_2018-7-6.tif</td>\n",
       "      <td>None</td>\n",
       "      <td>test</td>\n",
       "      <td>POLYGON ((12.01887 54.17417, 12.01869 54.17165...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>630 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    name_of_model  size_in_sq_m  peak_power date_of_data first_detection   \n",
       "0            test       29200.0       4.672   2018-01-01      2018-01-01  \\\n",
       "1            test       29200.0       4.672   2018-01-01      2018-01-01   \n",
       "2            test       29200.0       4.672   2018-01-01      2018-01-01   \n",
       "3            test       38700.0       6.192   2018-01-01      2018-01-01   \n",
       "4            test       97900.0      15.664   2018-01-01      2018-01-01   \n",
       "..            ...           ...         ...          ...             ...   \n",
       "625          test       41600.0       6.656   2018-01-01      2018-01-01   \n",
       "626          test       41600.0       6.656   2018-01-01      2018-01-01   \n",
       "627          test       83400.0      13.344   2018-01-01      2018-01-01   \n",
       "628          test       83400.0      13.344   2018-01-01      2018-01-01   \n",
       "629          test       83400.0      13.344   2018-01-01      2018-01-01   \n",
       "\n",
       "    last_detection  avg_confidence                name_in_aws is_valid   \n",
       "0       2018-01-01               0  32UMA_1034_2018-11-16.tif     None  \\\n",
       "1       2018-01-01               0   32UMA_1034_2018-4-20.tif     None   \n",
       "2       2018-01-01               0   32UMA_1034_2018-9-27.tif     None   \n",
       "3       2018-01-01               0  32UMA_1042_2018-11-16.tif     None   \n",
       "4       2018-01-01               0  32UMA_1042_2018-11-16.tif     None   \n",
       "..             ...             ...                        ...      ...   \n",
       "625     2018-01-01               0   32UPF_1622_2018-4-20.tif     None   \n",
       "626     2018-01-01               0    32UPF_1622_2018-7-6.tif     None   \n",
       "627     2018-01-01               0  32UPF_1623_2018-10-14.tif     None   \n",
       "628     2018-01-01               0   32UPF_1623_2018-4-20.tif     None   \n",
       "629     2018-01-01               0    32UPF_1623_2018-7-6.tif     None   \n",
       "\n",
       "    comment                                           geometry  \n",
       "0      test  POLYGON ((8.38072 50.02334, 8.38617 50.02337, ...  \n",
       "1      test  POLYGON ((8.38072 50.02334, 8.38617 50.02337, ...  \n",
       "2      test  POLYGON ((8.38072 50.02334, 8.38617 50.02337, ...  \n",
       "3      test  POLYGON ((8.64275 50.02427, 8.64303 50.02427, ...  \n",
       "4      test  POLYGON ((8.63968 50.02444, 8.64163 50.02444, ...  \n",
       "..      ...                                                ...  \n",
       "625    test  POLYGON ((12.01673 54.17422, 12.01780 54.17419...  \n",
       "626    test  POLYGON ((12.01673 54.17422, 12.01780 54.17419...  \n",
       "627    test  POLYGON ((12.01887 54.17417, 12.01869 54.17165...  \n",
       "628    test  POLYGON ((12.01887 54.17417, 12.01869 54.17165...  \n",
       "629    test  POLYGON ((12.01887 54.17417, 12.01869 54.17165...  \n",
       "\n",
       "[630 rows x 11 columns]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.set_geometry('geometry')\n",
    "\n",
    "df.to_file('testset.geojson', driver='GeoJSON')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
