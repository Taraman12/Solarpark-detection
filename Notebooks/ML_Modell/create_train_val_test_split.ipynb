{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the data on the disk into a train, validation and test set"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Create for each tile on folder which contains the folder from every season for this tile\n",
    "2. Random sample tiles for the train, validation and test set\n",
    "3. Copy the tiles from the disk to the train, validation and test folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import re\n",
    "import os\n",
    "import random\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "IDENTIFIER_REGEX = re.compile(\n",
    "    r\"\"\"(?P<mission>S2[A-B])_MSI\n",
    "        (?P<product_level>L[1-2][A-C])_\n",
    "        (?P<sensing_time>\\d{8}T\\d{6})_\n",
    "        (?P<processing_baseline>N\\d{4})_\n",
    "        (?P<relative_orbit>R\\d{3})_T\n",
    "        (?P<utm_code>\\d{2})\n",
    "        (?P<latitude_band>\\w{1})\n",
    "        (?P<square>\\w{2})_\n",
    "        (?P<year>\\d{4})\n",
    "        (?P<month>\\d{2})\n",
    "        (?P<day>\\d{2})T\n",
    "        (?P<product_time>\\d{6})\"\"\",\n",
    "    re.VERBOSE,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tile_and_date(identifier: str):\n",
    "    regex_match = re.search(IDENTIFIER_REGEX, identifier)\n",
    "\n",
    "    if not regex_match:\n",
    "        return None, None\n",
    "\n",
    "    utm_code = regex_match.group(\"utm_code\")\n",
    "    latitude_band = regex_match.group(\"latitude_band\")\n",
    "    square = regex_match.group(\"square\")\n",
    "    year = regex_match.group(\"year\")\n",
    "    # remove leading zeros\n",
    "    month = str(int(regex_match.group(\"month\")))\n",
    "    day = str(int(regex_match.group(\"day\")))\n",
    "\n",
    "    tile = f\"{utm_code}{latitude_band}{square}\"\n",
    "    tile_date = f\"{year}-{month}-{day}\"\n",
    "\n",
    "    return tile, tile_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_prepro_path = Path(r'C:\\Users\\Fabian\\Documents\\Github_Masterthesis\\Solarpark-detection\\data_local\\images_only_AOI_test_color_corr_cleaned')\n",
    "masks_prepro_path = Path(r'C:\\Users\\Fabian\\Documents\\Github_Masterthesis\\Solarpark-detection\\data_local\\masks_only_AOI_test_color_corr_cleaned')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a list of all tiles which are available on the disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def index_to_filename(image_dir: Path, set_list: list) -> list:\n",
    "    set_filenames = []\n",
    "    for file_path in image_dir.glob(\"*.pt\"):\n",
    "        tile, number, date = file_path.stem.split(\"_\")\n",
    "        if (tile, number) in set_list:\n",
    "            set_filenames.append(str(file_path))  # .name\n",
    "    return set_filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a list of all tiles\n",
    "tile_list = []\n",
    "for file_path in images_prepro_path.glob(\"*.pt\"):\n",
    "    filename = file_path.stem\n",
    "    tile, number, date = filename.split(\"_\")\n",
    "    tile_list.append(tile)\n",
    "\n",
    "# set is used to get unique values of tiles\n",
    "tiles_unique = list(set(tile_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select random tiles for train, val and test\n",
    "random.seed(42)\n",
    "random.shuffle(tiles_unique)\n",
    "\n",
    "num_total = len(tiles_unique)\n",
    "num_train = int(num_total * 0.7)\n",
    "num_val = int(num_total * 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create train, val and test list\n",
    "train_list = tiles_unique[:num_train]\n",
    "val_list = tiles_unique[num_train : num_train + num_val]\n",
    "test_list = tiles_unique[num_train + num_val :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a directory for each set\n",
    "train_dir = Path(r'C:\\Users\\Fabian\\Documents\\Github_Masterthesis\\Solarpark-detection\\data_local\\data_splitted')\n",
    "for set_name in [\"train\", \"val\", \"test\"]:\n",
    "    os.makedirs(train_dir / set_name, exist_ok=True)\n",
    "    os.makedirs(train_dir / set_name / \"images\", exist_ok=True)\n",
    "    os.makedirs(train_dir / set_name / \"masks\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in images_prepro_path.glob(\"*.pt\"):\n",
    "    file_stammed = file.stem\n",
    "    filename = file.name\n",
    "    tile, _, _ = file_stammed.split(\"_\")\n",
    "    if tile in train_list:\n",
    "        shutil.copyfile(images_prepro_path / filename, train_dir / \"train\" / \"images\" / filename)\n",
    "        shutil.copyfile(masks_prepro_path / filename, train_dir / \"train\" / \"masks\" / filename)\n",
    "    elif tile in val_list:\n",
    "        shutil.copyfile(images_prepro_path / filename, train_dir / \"val\" / \"images\" / filename)\n",
    "        shutil.copyfile(masks_prepro_path / filename, train_dir / \"val\" / \"masks\" / filename)\n",
    "    elif tile in test_list:\n",
    "        shutil.copyfile(images_prepro_path / filename, train_dir / \"test\" / \"images\" / filename)\n",
    "        shutil.copyfile(masks_prepro_path / filename, train_dir / \"test\" / \"masks\" / filename)\n",
    "    else:\n",
    "        print(\"Error: Tile not in any set!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of files in each set:\n",
      "Train images: 3832\n",
      "Train masks: 3832\n",
      "Val images: 489\n",
      "Val masks: 489\n",
      "Test images: 342\n",
      "Test masks: 342\n"
     ]
    }
   ],
   "source": [
    "# check if all files are copied\n",
    "print(\"Number of files in each set:\")\n",
    "print(f'Train images: {len(list(train_dir.glob(\"train/images/*.pt\")))}')\n",
    "print(f'Train masks: {len(list(train_dir.glob(\"train/masks/*.pt\")))}')\n",
    "print(f'Val images: {len(list(train_dir.glob(\"val/images/*.pt\")))}')\n",
    "print(f'Val masks: {len(list(train_dir.glob(\"val/masks/*.pt\")))}')\n",
    "print(f'Test images: {len(list(train_dir.glob(\"test/images/*.pt\")))}')\n",
    "print(f'Test masks: {len(list(train_dir.glob(\"test/masks/*.pt\")))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Sum of all files:\")\n",
    "print(f'Images: {len(list(train_dir.glob(\"**/*.pt\")))}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
