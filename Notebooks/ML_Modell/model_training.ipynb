{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional, Tuple, List, Dict, Any, Union\n",
    "import os\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "import glob\n",
    "import random\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import Adam\n",
    "from torch.optim.lr_scheduler import OneCycleLR\n",
    "from torchmetrics.classification import BinaryJaccardIndex, BinaryF1Score, Dice, BinaryPrecision, BinaryRecall\n",
    "# from torchvision import transforms\n",
    "import segmentation_models_pytorch as smp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GeoImageDataset(Dataset):\n",
    "    def __init__(self, img_dir, mask_dir, transform=None):\n",
    "        self.img_dir = img_dir\n",
    "        self.mask_dir = mask_dir\n",
    "        self.img_files = os.listdir(self.img_dir)\n",
    "        self.mask_files = os.listdir(self.mask_dir)\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Load image\n",
    "        img_path = os.path.join(self.img_dir, self.img_files[idx])\n",
    "        # mask and img_file have so far the same name\n",
    "        mask_path = os.path.join(self.mask_dir, self.img_files[idx])\n",
    "        img = torch.load(img_path)\n",
    "        # converts bool mask into integer (0/1)\n",
    "        mask = torch.load(mask_path).long()\n",
    "        # Apply transform (if any)\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "            mask = self.transform(mask)\n",
    "\n",
    "        return img, mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer:\n",
    "    def __init__(self, loss_fn, max_lr, epochs, transform):\n",
    "        # self.model = model\n",
    "        self.loss_fn = loss_fn\n",
    "        self.max_lr = max_lr\n",
    "        self.epochs = epochs\n",
    "        self.transform = transform\n",
    "\n",
    "        self.train_loss_steps = []\n",
    "        self.validation_loss_steps = []\n",
    "        self.validation_dice_steps = []\n",
    "        self.validation_f1_epochs = []\n",
    "        self.validation_precision_epochs = []\n",
    "        self.validation_recall_epochs = []\n",
    "\n",
    "        self.train_loss_epochs = []\n",
    "        self.val_loss_epochs = []\n",
    "        self.val_dice_epochs = []\n",
    "\n",
    "        self.device = (\n",
    "            \"cuda\"\n",
    "            if torch.cuda.is_available()\n",
    "            else \"mps\"\n",
    "            if torch.backends.mps.is_available()\n",
    "            else \"cpu\"\n",
    "        )\n",
    "\n",
    "    def train_and_save(self, model, train_dataloader, val_dataloader, sampling, validated, backbone, batch_size):\n",
    "        optimizer = Adam(model.parameters(), lr=self.max_lr)\n",
    "\n",
    "        scheduler = OneCycleLR(\n",
    "            optimizer,\n",
    "            max_lr=self.max_lr,\n",
    "            steps_per_epoch=len(train_dataloader),\n",
    "            epochs=self.epochs,\n",
    "        )\n",
    "        filename = f\"u_net_{sampling}_{validated}_{backbone}_{self.epochs}_{batch_size}_{self.max_lr}_{self.transform}\"\n",
    "        for t in range(self.epochs):\n",
    "            print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "            loss, train_loss = self.train(model, train_dataloader, optimizer)\n",
    "            self.train_loss_steps.extend(train_loss)\n",
    "            self.train_loss_epochs.append(loss)\n",
    "            loss, val_loss, dice, dice_list, f1_score, precision, recall = self.test(model, val_dataloader)\n",
    "            self.validation_loss_steps.extend(val_loss)\n",
    "            self.val_loss_epochs.append(loss)\n",
    "            self.val_dice_epochs.append(dice)\n",
    "            self.validation_dice_steps.extend(dice_list)\n",
    "            self.validation_f1_epochs.append(f1_score)\n",
    "            self.validation_precision_epochs.append(precision)\n",
    "            self.validation_recall_epochs.append(recall)\n",
    "            if dice >= np.max(self.val_dice_epochs):\n",
    "                torch.save(\n",
    "                    model.state_dict(),\n",
    "                    f\"models/{filename}_best_model.pt\",\n",
    "                )\n",
    "                print(\"Model saved!\")\n",
    "            scheduler.step()\n",
    "\n",
    "        \n",
    "        data_dict = {\n",
    "            \"train_loss_epochs\": self.train_loss_epochs,\n",
    "            \"val_loss_epochs\": self.val_loss_epochs,\n",
    "            \"val_dice_epochs\": self.val_dice_epochs,\n",
    "            \"validation_f1_epochs\": self.validation_f1_epochs,\n",
    "            \"validation_precision_epochs\": self.validation_precision_epochs,\n",
    "            \"validation_recall_epochs\": self.validation_recall_epochs,\n",
    "        }\n",
    "        self.save_as_csv(data_dict, f\"trainings_results/{filename}\")\n",
    "        steps_dict = {\n",
    "            \"train_loss_steps\": self.train_loss_steps,\n",
    "            \"validation_loss_steps\": self.validation_loss_steps,\n",
    "            \"validation_dice_steps\": self.validation_dice_steps,\n",
    "        }\n",
    "        data_dict.update(steps_dict)\n",
    "        self.save_as_pickle(data_dict, f\"trainings_results/{filename}\")\n",
    "        torch.save(model.state_dict(), f\"models/{filename}.pt\")\n",
    "\n",
    "    def train(\n",
    "        self,\n",
    "        model: nn.Module,\n",
    "        dataloader: Any,\n",
    "        optimizer: Any,\n",
    "    ) -> Union[torch.Tensor, List[float]]:\n",
    "        size = len(dataloader.dataset)\n",
    "        loss_vals= []\n",
    "        model.train()\n",
    "        for batch, (X, y) in enumerate(dataloader):\n",
    "            X, y = X.to(self.device), y.to(self.device)\n",
    "\n",
    "            pred = model(X)\n",
    "            \n",
    "            loss = self.loss_fn(pred, y.to(torch.float32)) # pred.squeeze(1)\n",
    "            loss_vals.append(loss.item())\n",
    "            # Backpropagation\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            if batch % 20 == 0:\n",
    "                loss, current = loss.item(), (batch + 1) * len(X)\n",
    "                \n",
    "                print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "        avg_loss = np.mean(loss_vals)\n",
    "        return avg_loss, loss_vals\n",
    "\n",
    "    def test(\n",
    "            self, \n",
    "            model: nn.Module, \n",
    "            dataloader: Any\n",
    "        ) -> Union[torch.Tensor, torch.Tensor, List[float]]:\n",
    "        loss_vals=  []\n",
    "        Dice_idx_vals = []\n",
    "        # size = len(dataloader.dataset)\n",
    "        num_batches = len(dataloader)\n",
    "        model.eval()\n",
    "        test_loss = 0\n",
    "        test_dice = 0\n",
    "        test_f1 = 0\n",
    "        test_precision = 0\n",
    "        test_recall = 0\n",
    "        metric = Dice(zero_division=1).to(self.device)\n",
    "        f1_score = BinaryF1Score(multidim_average='global').to(self.device)\n",
    "        precision = BinaryPrecision(multidim_average='global').to(self.device)\n",
    "        recall = BinaryRecall(multidim_average='global').to(self.device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for X, y in dataloader:\n",
    "                X, y = X.to(device), y.to(device)\n",
    "                pred = model(X)\n",
    "                loss = self.loss_fn(pred, y.to(torch.float32)).item() # pred.squeeze(1)\n",
    "                test_loss += loss\n",
    "                dice = metric(pred, y.to(torch.int8))\n",
    "                loss_vals.append(loss)\n",
    "                test_dice += dice.item()\n",
    "                Dice_idx_vals.append(dice.item())\n",
    "                test_f1 += f1_score(pred, y.to(torch.int8)).item()\n",
    "                test_precision += precision(pred, y.to(torch.int8)).item()\n",
    "                test_recall += recall(pred, y.to(torch.int8)).item()\n",
    "\n",
    "        test_loss /= num_batches\n",
    "        test_dice /= num_batches\n",
    "        test_f1 /= num_batches\n",
    "        test_precision /= num_batches\n",
    "        test_recall /= num_batches\n",
    "        # correct /= size\n",
    "\n",
    "        # Dice_idx = 100 * metric(pred, y)\n",
    "        print(\n",
    "            f\"Test Error: \\n\"\n",
    "            f\"Dice-Coefficient: {test_dice:>0.2f}, Avg loss: {test_loss:>5f} \\n\"\n",
    "        )\n",
    "\n",
    "        return test_loss, loss_vals, test_dice, Dice_idx_vals, test_f1, test_precision, test_recall\n",
    "\n",
    "    def save_as_csv(self, data_dict: dict, filename: str) -> None:\n",
    "        df = pd.DataFrame.from_dict(data_dict)\n",
    "        df.to_csv(f\"{filename}.csv\", index=False)\n",
    "\n",
    "    def save_as_pickle(self, data_dict: dict, filename: str) -> None:\n",
    "        with open(f\"{filename}.pkl\", 'wb') as f:\n",
    "            pickle.dump(data_dict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = Path(r\"C:\\Users\\Fabian\\Documents\\Github_Masterthesis\\Solarpark-detection\\data_local\\data_splitted_undersampling_refactored_not_color_cleaned\")\n",
    "\n",
    "train_images_path = Path(root / \"train/images\")\n",
    "train_masks_path = Path(root / \"train/masks\")\n",
    "val_images_path = Path(root / \"val/images\")\n",
    "val_masks_path = Path(root / \"val/masks\")\n",
    "test_images_path = Path(root / \"test/images\")\n",
    "test_masks_path = Path(root / \"test/masks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = None\n",
    "train_dataset = GeoImageDataset(train_images_path, train_masks_path, transform=transform)\n",
    "val_dataset = GeoImageDataset(val_images_path, val_masks_path, transform=transform)\n",
    "test_dataset = GeoImageDataset(test_images_path, test_masks_path, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "shuffle = True\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=shuffle)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=shuffle)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=shuffle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size train set: 13472\n",
      "Size val set: 3790\n",
      "Size test set: 2213\n"
     ]
    }
   ],
   "source": [
    "print(f\"Size train set: {train_dataset.__len__()}\")\n",
    "print(f\"Size val set: {val_dataset.__len__()}\")\n",
    "print(f\"Size test set: {test_dataset.__len__()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 0.883835  [   32/13472]\n",
      "loss: 0.400794  [  672/13472]\n",
      "loss: 0.236435  [ 1312/13472]\n",
      "loss: 0.152067  [ 1952/13472]\n",
      "loss: 0.108940  [ 2592/13472]\n",
      "loss: 0.086918  [ 3232/13472]\n",
      "loss: 0.071116  [ 3872/13472]\n",
      "loss: 0.066269  [ 4512/13472]\n",
      "loss: 0.062043  [ 5152/13472]\n",
      "loss: 0.055427  [ 5792/13472]\n",
      "loss: 0.042748  [ 6432/13472]\n",
      "loss: 0.035058  [ 7072/13472]\n",
      "loss: 0.054732  [ 7712/13472]\n",
      "loss: 0.026789  [ 8352/13472]\n",
      "loss: 0.029717  [ 8992/13472]\n",
      "loss: 0.032248  [ 9632/13472]\n",
      "loss: 0.039837  [10272/13472]\n",
      "loss: 0.022128  [10912/13472]\n",
      "loss: 0.022999  [11552/13472]\n",
      "loss: 0.018790  [12192/13472]\n",
      "loss: 0.018710  [12832/13472]\n",
      "loss: 0.015033  [13472/13472]\n",
      "Test Error: \n",
      "Dice-Coefficient: 0.00, Avg loss: 0.020892 \n",
      "\n",
      "Model saved!\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 0.016574  [   32/13472]\n",
      "loss: 0.016561  [  672/13472]\n",
      "loss: 0.016449  [ 1312/13472]\n",
      "loss: 0.014803  [ 1952/13472]\n",
      "loss: 0.015724  [ 2592/13472]\n",
      "loss: 0.010109  [ 3232/13472]\n",
      "loss: 0.017554  [ 3872/13472]\n",
      "loss: 0.009807  [ 4512/13472]\n",
      "loss: 0.008061  [ 5152/13472]\n",
      "loss: 0.011296  [ 5792/13472]\n",
      "loss: 0.009981  [ 6432/13472]\n",
      "loss: 0.016625  [ 7072/13472]\n",
      "loss: 0.008164  [ 7712/13472]\n",
      "loss: 0.007535  [ 8352/13472]\n",
      "loss: 0.014075  [ 8992/13472]\n",
      "loss: 0.014027  [ 9632/13472]\n",
      "loss: 0.009413  [10272/13472]\n",
      "loss: 0.008552  [10912/13472]\n",
      "loss: 0.005019  [11552/13472]\n",
      "loss: 0.008255  [12192/13472]\n",
      "loss: 0.007568  [12832/13472]\n",
      "loss: 0.007174  [13472/13472]\n",
      "Test Error: \n",
      "Dice-Coefficient: 0.68, Avg loss: 0.009851 \n",
      "\n",
      "Model saved!\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.004854  [   32/13472]\n",
      "loss: 0.010473  [  672/13472]\n",
      "loss: 0.007175  [ 1312/13472]\n",
      "loss: 0.009789  [ 1952/13472]\n",
      "loss: 0.006668  [ 2592/13472]\n",
      "loss: 0.006952  [ 3232/13472]\n",
      "loss: 0.007602  [ 3872/13472]\n",
      "loss: 0.005965  [ 4512/13472]\n",
      "loss: 0.010535  [ 5152/13472]\n",
      "loss: 0.008943  [ 5792/13472]\n",
      "loss: 0.007198  [ 6432/13472]\n",
      "loss: 0.004983  [ 7072/13472]\n",
      "loss: 0.008357  [ 7712/13472]\n",
      "loss: 0.004619  [ 8352/13472]\n",
      "loss: 0.004862  [ 8992/13472]\n",
      "loss: 0.008747  [ 9632/13472]\n",
      "loss: 0.009713  [10272/13472]\n",
      "loss: 0.004829  [10912/13472]\n",
      "loss: 0.010102  [11552/13472]\n",
      "loss: 0.007185  [12192/13472]\n",
      "loss: 0.005006  [12832/13472]\n",
      "loss: 0.006000  [13472/13472]\n",
      "Test Error: \n",
      "Dice-Coefficient: 0.70, Avg loss: 0.008268 \n",
      "\n",
      "Model saved!\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.005514  [   32/13472]\n",
      "loss: 0.007321  [  672/13472]\n",
      "loss: 0.006663  [ 1312/13472]\n",
      "loss: 0.011924  [ 1952/13472]\n",
      "loss: 0.004574  [ 2592/13472]\n",
      "loss: 0.003851  [ 3232/13472]\n",
      "loss: 0.004296  [ 3872/13472]\n",
      "loss: 0.009452  [ 4512/13472]\n",
      "loss: 0.005707  [ 5152/13472]\n",
      "loss: 0.005188  [ 5792/13472]\n",
      "loss: 0.006210  [ 6432/13472]\n",
      "loss: 0.002950  [ 7072/13472]\n",
      "loss: 0.003868  [ 7712/13472]\n",
      "loss: 0.004412  [ 8352/13472]\n",
      "loss: 0.004986  [ 8992/13472]\n",
      "loss: 0.005375  [ 9632/13472]\n",
      "loss: 0.010090  [10272/13472]\n",
      "loss: 0.007480  [10912/13472]\n",
      "loss: 0.005792  [11552/13472]\n",
      "loss: 0.006055  [12192/13472]\n",
      "loss: 0.004551  [12832/13472]\n",
      "loss: 0.007475  [13472/13472]\n",
      "Test Error: \n",
      "Dice-Coefficient: 0.75, Avg loss: 0.007109 \n",
      "\n",
      "Model saved!\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.005766  [   32/13472]\n",
      "loss: 0.003368  [  672/13472]\n",
      "loss: 0.006721  [ 1312/13472]\n",
      "loss: 0.006305  [ 1952/13472]\n",
      "loss: 0.005038  [ 2592/13472]\n",
      "loss: 0.003386  [ 3232/13472]\n",
      "loss: 0.004195  [ 3872/13472]\n",
      "loss: 0.005065  [ 4512/13472]\n",
      "loss: 0.003597  [ 5152/13472]\n",
      "loss: 0.010988  [ 5792/13472]\n",
      "loss: 0.004197  [ 6432/13472]\n",
      "loss: 0.007834  [ 7072/13472]\n",
      "loss: 0.004008  [ 7712/13472]\n",
      "loss: 0.002292  [ 8352/13472]\n",
      "loss: 0.008106  [ 8992/13472]\n",
      "loss: 0.005054  [ 9632/13472]\n",
      "loss: 0.006218  [10272/13472]\n",
      "loss: 0.002675  [10912/13472]\n",
      "loss: 0.002782  [11552/13472]\n",
      "loss: 0.008163  [12192/13472]\n",
      "loss: 0.005078  [12832/13472]\n",
      "loss: 0.002495  [13472/13472]\n",
      "Test Error: \n",
      "Dice-Coefficient: 0.74, Avg loss: 0.006715 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 0.002962  [   32/13472]\n",
      "loss: 0.003080  [  672/13472]\n",
      "loss: 0.002289  [ 1312/13472]\n",
      "loss: 0.005650  [ 1952/13472]\n",
      "loss: 0.001708  [ 2592/13472]\n",
      "loss: 0.003721  [ 3232/13472]\n",
      "loss: 0.002555  [ 3872/13472]\n",
      "loss: 0.004306  [ 4512/13472]\n",
      "loss: 0.005089  [ 5152/13472]\n",
      "loss: 0.007446  [ 5792/13472]\n",
      "loss: 0.003999  [ 6432/13472]\n",
      "loss: 0.005094  [ 7072/13472]\n",
      "loss: 0.003288  [ 7712/13472]\n",
      "loss: 0.012507  [ 8352/13472]\n",
      "loss: 0.003153  [ 8992/13472]\n",
      "loss: 0.006911  [ 9632/13472]\n",
      "loss: 0.004306  [10272/13472]\n",
      "loss: 0.004454  [10912/13472]\n",
      "loss: 0.004194  [11552/13472]\n",
      "loss: 0.003348  [12192/13472]\n",
      "loss: 0.002463  [12832/13472]\n",
      "loss: 0.002183  [13472/13472]\n",
      "Test Error: \n",
      "Dice-Coefficient: 0.78, Avg loss: 0.006187 \n",
      "\n",
      "Model saved!\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 0.002830  [   32/13472]\n",
      "loss: 0.002146  [  672/13472]\n",
      "loss: 0.003618  [ 1312/13472]\n",
      "loss: 0.003451  [ 1952/13472]\n",
      "loss: 0.006659  [ 2592/13472]\n",
      "loss: 0.002467  [ 3232/13472]\n",
      "loss: 0.001301  [ 3872/13472]\n",
      "loss: 0.003172  [ 4512/13472]\n",
      "loss: 0.004485  [ 5152/13472]\n",
      "loss: 0.002327  [ 5792/13472]\n",
      "loss: 0.007277  [ 6432/13472]\n",
      "loss: 0.000793  [ 7072/13472]\n",
      "loss: 0.004494  [ 7712/13472]\n",
      "loss: 0.003677  [ 8352/13472]\n",
      "loss: 0.006439  [ 8992/13472]\n",
      "loss: 0.002010  [ 9632/13472]\n",
      "loss: 0.001996  [10272/13472]\n",
      "loss: 0.002793  [10912/13472]\n",
      "loss: 0.004702  [11552/13472]\n",
      "loss: 0.005122  [12192/13472]\n",
      "loss: 0.004953  [12832/13472]\n",
      "loss: 0.001615  [13472/13472]\n",
      "Test Error: \n",
      "Dice-Coefficient: 0.74, Avg loss: 0.007356 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.004856  [   32/13472]\n",
      "loss: 0.002584  [  672/13472]\n",
      "loss: 0.004271  [ 1312/13472]\n",
      "loss: 0.002828  [ 1952/13472]\n",
      "loss: 0.004092  [ 2592/13472]\n",
      "loss: 0.001386  [ 3232/13472]\n",
      "loss: 0.003306  [ 3872/13472]\n",
      "loss: 0.003488  [ 4512/13472]\n",
      "loss: 0.003610  [ 5152/13472]\n",
      "loss: 0.001011  [ 5792/13472]\n",
      "loss: 0.004945  [ 6432/13472]\n",
      "loss: 0.003391  [ 7072/13472]\n",
      "loss: 0.004230  [ 7712/13472]\n",
      "loss: 0.002345  [ 8352/13472]\n",
      "loss: 0.002417  [ 8992/13472]\n",
      "loss: 0.006122  [ 9632/13472]\n",
      "loss: 0.002851  [10272/13472]\n",
      "loss: 0.001006  [10912/13472]\n",
      "loss: 0.004649  [11552/13472]\n",
      "loss: 0.002113  [12192/13472]\n",
      "loss: 0.005157  [12832/13472]\n",
      "loss: 0.002244  [13472/13472]\n",
      "Test Error: \n",
      "Dice-Coefficient: 0.77, Avg loss: 0.006381 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.004104  [   32/13472]\n",
      "loss: 0.001276  [  672/13472]\n",
      "loss: 0.002946  [ 1312/13472]\n",
      "loss: 0.007200  [ 1952/13472]\n",
      "loss: 0.005978  [ 2592/13472]\n",
      "loss: 0.002540  [ 3232/13472]\n",
      "loss: 0.001233  [ 3872/13472]\n",
      "loss: 0.001309  [ 4512/13472]\n",
      "loss: 0.011957  [ 5152/13472]\n",
      "loss: 0.002565  [ 5792/13472]\n",
      "loss: 0.000840  [ 6432/13472]\n",
      "loss: 0.001285  [ 7072/13472]\n",
      "loss: 0.006413  [ 7712/13472]\n",
      "loss: 0.002391  [ 8352/13472]\n",
      "loss: 0.007447  [ 8992/13472]\n",
      "loss: 0.002482  [ 9632/13472]\n",
      "loss: 0.002278  [10272/13472]\n",
      "loss: 0.001852  [10912/13472]\n",
      "loss: 0.002021  [11552/13472]\n",
      "loss: 0.004731  [12192/13472]\n",
      "loss: 0.004078  [12832/13472]\n",
      "loss: 0.002509  [13472/13472]\n",
      "Test Error: \n",
      "Dice-Coefficient: 0.72, Avg loss: 0.008428 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.001913  [   32/13472]\n",
      "loss: 0.002295  [  672/13472]\n",
      "loss: 0.002643  [ 1312/13472]\n",
      "loss: 0.003082  [ 1952/13472]\n",
      "loss: 0.004994  [ 2592/13472]\n",
      "loss: 0.002191  [ 3232/13472]\n",
      "loss: 0.004094  [ 3872/13472]\n",
      "loss: 0.002246  [ 4512/13472]\n",
      "loss: 0.002904  [ 5152/13472]\n",
      "loss: 0.002175  [ 5792/13472]\n",
      "loss: 0.001989  [ 6432/13472]\n",
      "loss: 0.001766  [ 7072/13472]\n",
      "loss: 0.004927  [ 7712/13472]\n",
      "loss: 0.000562  [ 8352/13472]\n",
      "loss: 0.002143  [ 8992/13472]\n",
      "loss: 0.002182  [ 9632/13472]\n",
      "loss: 0.000896  [10272/13472]\n",
      "loss: 0.001294  [10912/13472]\n",
      "loss: 0.004079  [11552/13472]\n",
      "loss: 0.001210  [12192/13472]\n",
      "loss: 0.001530  [12832/13472]\n",
      "loss: 0.003245  [13472/13472]\n",
      "Test Error: \n",
      "Dice-Coefficient: 0.75, Avg loss: 0.007325 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "loss: 0.001110  [   32/13472]\n",
      "loss: 0.001321  [  672/13472]\n",
      "loss: 0.003169  [ 1312/13472]\n",
      "loss: 0.002130  [ 1952/13472]\n",
      "loss: 0.004890  [ 2592/13472]\n",
      "loss: 0.001967  [ 3232/13472]\n",
      "loss: 0.002251  [ 3872/13472]\n",
      "loss: 0.004886  [ 4512/13472]\n",
      "loss: 0.003302  [ 5152/13472]\n",
      "loss: 0.007720  [ 5792/13472]\n",
      "loss: 0.002888  [ 6432/13472]\n",
      "loss: 0.005596  [ 7072/13472]\n",
      "loss: 0.002851  [ 7712/13472]\n",
      "loss: 0.002539  [ 8352/13472]\n",
      "loss: 0.001752  [ 8992/13472]\n",
      "loss: 0.004468  [ 9632/13472]\n",
      "loss: 0.003781  [10272/13472]\n",
      "loss: 0.004191  [10912/13472]\n",
      "loss: 0.001842  [11552/13472]\n",
      "loss: 0.002608  [12192/13472]\n",
      "loss: 0.002340  [12832/13472]\n",
      "loss: 0.001997  [13472/13472]\n",
      "Test Error: \n",
      "Dice-Coefficient: 0.73, Avg loss: 0.007244 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "loss: 0.003396  [   32/13472]\n",
      "loss: 0.002673  [  672/13472]\n",
      "loss: 0.001530  [ 1312/13472]\n",
      "loss: 0.002625  [ 1952/13472]\n",
      "loss: 0.001056  [ 2592/13472]\n",
      "loss: 0.002034  [ 3232/13472]\n",
      "loss: 0.001297  [ 3872/13472]\n",
      "loss: 0.002198  [ 4512/13472]\n",
      "loss: 0.003597  [ 5152/13472]\n",
      "loss: 0.000957  [ 5792/13472]\n",
      "loss: 0.001739  [ 6432/13472]\n",
      "loss: 0.004956  [ 7072/13472]\n",
      "loss: 0.001188  [ 7712/13472]\n",
      "loss: 0.003208  [ 8352/13472]\n",
      "loss: 0.003002  [ 8992/13472]\n",
      "loss: 0.001432  [ 9632/13472]\n",
      "loss: 0.001023  [10272/13472]\n",
      "loss: 0.002088  [10912/13472]\n",
      "loss: 0.001766  [11552/13472]\n",
      "loss: 0.002438  [12192/13472]\n",
      "loss: 0.001120  [12832/13472]\n",
      "loss: 0.001081  [13472/13472]\n",
      "Test Error: \n",
      "Dice-Coefficient: 0.76, Avg loss: 0.007573 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "loss: 0.001242  [   32/13472]\n",
      "loss: 0.001099  [  672/13472]\n",
      "loss: 0.002567  [ 1312/13472]\n",
      "loss: 0.002130  [ 1952/13472]\n",
      "loss: 0.000863  [ 2592/13472]\n",
      "loss: 0.000800  [ 3232/13472]\n",
      "loss: 0.001077  [ 3872/13472]\n",
      "loss: 0.006967  [ 4512/13472]\n",
      "loss: 0.003394  [ 5152/13472]\n",
      "loss: 0.003226  [ 5792/13472]\n",
      "loss: 0.002587  [ 6432/13472]\n",
      "loss: 0.002290  [ 7072/13472]\n",
      "loss: 0.003148  [ 7712/13472]\n",
      "loss: 0.008623  [ 8352/13472]\n",
      "loss: 0.005524  [ 8992/13472]\n",
      "loss: 0.002033  [ 9632/13472]\n",
      "loss: 0.001747  [10272/13472]\n",
      "loss: 0.002620  [10912/13472]\n",
      "loss: 0.005821  [11552/13472]\n",
      "loss: 0.001399  [12192/13472]\n",
      "loss: 0.001907  [12832/13472]\n",
      "loss: 0.003629  [13472/13472]\n",
      "Test Error: \n",
      "Dice-Coefficient: 0.76, Avg loss: 0.007431 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "loss: 0.002001  [   32/13472]\n",
      "loss: 0.001844  [  672/13472]\n",
      "loss: 0.001904  [ 1312/13472]\n",
      "loss: 0.001671  [ 1952/13472]\n",
      "loss: 0.001556  [ 2592/13472]\n",
      "loss: 0.001628  [ 3232/13472]\n",
      "loss: 0.002845  [ 3872/13472]\n",
      "loss: 0.001048  [ 4512/13472]\n",
      "loss: 0.001328  [ 5152/13472]\n",
      "loss: 0.001707  [ 5792/13472]\n",
      "loss: 0.003393  [ 6432/13472]\n",
      "loss: 0.001695  [ 7072/13472]\n",
      "loss: 0.000584  [ 7712/13472]\n",
      "loss: 0.001245  [ 8352/13472]\n",
      "loss: 0.001990  [ 8992/13472]\n",
      "loss: 0.002911  [ 9632/13472]\n",
      "loss: 0.000819  [10272/13472]\n",
      "loss: 0.001005  [10912/13472]\n",
      "loss: 0.001208  [11552/13472]\n",
      "loss: 0.000830  [12192/13472]\n",
      "loss: 0.002873  [12832/13472]\n",
      "loss: 0.001446  [13472/13472]\n",
      "Test Error: \n",
      "Dice-Coefficient: 0.71, Avg loss: 0.008443 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "loss: 0.001320  [   32/13472]\n",
      "loss: 0.001412  [  672/13472]\n",
      "loss: 0.001029  [ 1312/13472]\n",
      "loss: 0.004907  [ 1952/13472]\n",
      "loss: 0.001841  [ 2592/13472]\n",
      "loss: 0.001205  [ 3232/13472]\n",
      "loss: 0.001926  [ 3872/13472]\n",
      "loss: 0.000370  [ 4512/13472]\n",
      "loss: 0.000498  [ 5152/13472]\n",
      "loss: 0.001944  [ 5792/13472]\n",
      "loss: 0.001106  [ 6432/13472]\n",
      "loss: 0.002642  [ 7072/13472]\n",
      "loss: 0.004650  [ 7712/13472]\n",
      "loss: 0.000829  [ 8352/13472]\n",
      "loss: 0.000715  [ 8992/13472]\n",
      "loss: 0.001454  [ 9632/13472]\n",
      "loss: 0.001685  [10272/13472]\n",
      "loss: 0.001387  [10912/13472]\n",
      "loss: 0.002133  [11552/13472]\n",
      "loss: 0.000561  [12192/13472]\n",
      "loss: 0.000679  [12832/13472]\n",
      "loss: 0.001349  [13472/13472]\n",
      "Test Error: \n",
      "Dice-Coefficient: 0.73, Avg loss: 0.008557 \n",
      "\n",
      "Model timm-resnest14d trained and saved\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "loss_fn = nn.BCELoss()\n",
    "sampling = \"undersampling\"\n",
    "validated = \"cleaned_verified\"\n",
    "epochs = 15\n",
    "transform = \"None\"\n",
    "max_lr = 0.01\n",
    "\n",
    "for backbone in [\"timm-resnest14d\"]:\n",
    "    model = smp.Unet(\n",
    "        encoder_name=backbone,\n",
    "        encoder_weights='imagenet',\n",
    "        in_channels=4,\n",
    "        classes=1,\n",
    "        activation='sigmoid',\n",
    "    ).to(device)\n",
    "    trainer = Trainer(loss_fn, max_lr=max_lr, epochs=epochs, transform=transform)\n",
    "    trainer.train_and_save(model, train_dataloader, val_dataloader, sampling, validated, backbone, batch_size)\n",
    "    print(f\"Model {backbone} trained and saved\")\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
