{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional, Tuple, List, Dict, Any, Union\n",
    "import os\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "import glob\n",
    "import random\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import Adam\n",
    "from torch.optim.lr_scheduler import OneCycleLR\n",
    "from torchmetrics.classification import BinaryJaccardIndex, BinaryF1Score, Dice, BinaryPrecision, BinaryRecall\n",
    "from torchvision import transforms\n",
    "import segmentation_models_pytorch as smp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GeoImageDataset(Dataset):\n",
    "    def __init__(self, img_dir, mask_dir, transform=None):\n",
    "        self.img_dir = img_dir\n",
    "        self.mask_dir = mask_dir\n",
    "        self.img_files = os.listdir(self.img_dir)\n",
    "        self.mask_files = os.listdir(self.mask_dir)\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Load image\n",
    "        img_path = os.path.join(self.img_dir, self.img_files[idx])\n",
    "        # mask and img_file have so far the same name\n",
    "        mask_path = os.path.join(self.mask_dir, self.img_files[idx])\n",
    "        img = torch.load(img_path)\n",
    "        # converts bool mask into integer (0/1)\n",
    "        mask = torch.load(mask_path).long()\n",
    "        # Apply transform (if any)\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "            mask = self.transform(mask)\n",
    "\n",
    "        return img, mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer:\n",
    "    def __init__(self, loss_fn, max_lr, epochs, transform):\n",
    "        # self.model = model\n",
    "        self.loss_fn = loss_fn\n",
    "        self.max_lr = max_lr\n",
    "        self.epochs = epochs\n",
    "        self.transform = transform\n",
    "\n",
    "        self.train_loss_steps = []\n",
    "        self.validation_loss_steps = []\n",
    "        self.validation_dice_steps = []\n",
    "        self.validation_f1_epochs = []\n",
    "        self.validation_precision_epochs = []\n",
    "        self.validation_recall_epochs = []\n",
    "\n",
    "        self.train_loss_epochs = []\n",
    "        self.val_loss_epochs = []\n",
    "        self.val_dice_epochs = []\n",
    "\n",
    "        self.device = (\n",
    "            \"cuda\"\n",
    "            if torch.cuda.is_available()\n",
    "            else \"mps\"\n",
    "            if torch.backends.mps.is_available()\n",
    "            else \"cpu\"\n",
    "        )\n",
    "\n",
    "    def train_and_save(self, model, train_dataloader, val_dataloader, sampling, validated, backbone, batch_size):\n",
    "        optimizer = Adam(model.parameters(), lr=self.max_lr)\n",
    "\n",
    "        scheduler = OneCycleLR(\n",
    "            optimizer,\n",
    "            max_lr=self.max_lr,\n",
    "            steps_per_epoch=len(train_dataloader),\n",
    "            epochs=self.epochs,\n",
    "        )\n",
    "        filename = f\"u_net_{sampling}_{validated}_{backbone}_{self.epochs}_{batch_size}_{self.max_lr}_{self.transform}\"\n",
    "        for t in range(self.epochs):\n",
    "            print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "            loss, train_loss = self.train(model, train_dataloader, optimizer)\n",
    "            self.train_loss_steps.extend(train_loss)\n",
    "            self.train_loss_epochs.append(loss)\n",
    "            loss, val_loss, dice, dice_list, f1_score, precision, recall = self.test(model, val_dataloader)\n",
    "            self.validation_loss_steps.extend(val_loss)\n",
    "            self.val_loss_epochs.append(loss)\n",
    "            self.val_dice_epochs.append(dice)\n",
    "            self.validation_dice_steps.extend(dice_list)\n",
    "            self.validation_f1_epochs.append(f1_score)\n",
    "            self.validation_precision_epochs.append(precision)\n",
    "            self.validation_recall_epochs.append(recall)\n",
    "            if dice >= np.max(self.val_dice_epochs):\n",
    "                torch.save(\n",
    "                    model.state_dict(),\n",
    "                    f\"models/{filename}_best_model.pt\",\n",
    "                )\n",
    "                print(\"Model saved!\")\n",
    "            scheduler.step()\n",
    "\n",
    "        \n",
    "        data_dict = {\n",
    "            \"train_loss_epochs\": self.train_loss_epochs,\n",
    "            \"val_loss_epochs\": self.val_loss_epochs,\n",
    "            \"val_dice_epochs\": self.val_dice_epochs,\n",
    "            \"validation_f1_epochs\": self.validation_f1_epochs,\n",
    "            \"validation_precision_epochs\": self.validation_precision_epochs,\n",
    "            \"validation_recall_epochs\": self.validation_recall_epochs,\n",
    "        }\n",
    "        self.save_as_csv(data_dict, f\"trainings_results/{filename}\")\n",
    "        steps_dict = {\n",
    "            \"train_loss_steps\": self.train_loss_steps,\n",
    "            \"validation_loss_steps\": self.validation_loss_steps,\n",
    "            \"validation_dice_steps\": self.validation_dice_steps,\n",
    "        }\n",
    "        data_dict.update(steps_dict)\n",
    "        self.save_as_pickle(data_dict, f\"trainings_results/{filename}\")\n",
    "        torch.save(model.state_dict(), f\"models/{filename}.pt\")\n",
    "\n",
    "    def train(\n",
    "        self,\n",
    "        model: nn.Module,\n",
    "        dataloader: Any,\n",
    "        optimizer: Any,\n",
    "    ) -> Union[torch.Tensor, List[float]]:\n",
    "        size = len(dataloader.dataset)\n",
    "        loss_vals= []\n",
    "        model.train()\n",
    "        for batch, (X, y) in enumerate(dataloader):\n",
    "            X, y = X.to(self.device), y.to(self.device)\n",
    "\n",
    "            pred = model(X)\n",
    "            \n",
    "            loss = self.loss_fn(pred, y.to(torch.float32)) # pred.squeeze(1)\n",
    "            loss_vals.append(loss.item())\n",
    "            # Backpropagation\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            if batch % 20 == 0:\n",
    "                loss, current = loss.item(), (batch + 1) * len(X)\n",
    "                \n",
    "                print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "        avg_loss = np.mean(loss_vals)\n",
    "        return avg_loss, loss_vals\n",
    "\n",
    "    def test(\n",
    "            self, \n",
    "            model: nn.Module, \n",
    "            dataloader: Any\n",
    "        ) -> Union[torch.Tensor, torch.Tensor, List[float]]:\n",
    "        loss_vals=  []\n",
    "        Dice_idx_vals = []\n",
    "        # size = len(dataloader.dataset)\n",
    "        num_batches = len(dataloader)\n",
    "        model.eval()\n",
    "        test_loss = 0\n",
    "        test_dice = 0\n",
    "        test_f1 = 0\n",
    "        test_precision = 0\n",
    "        test_recall = 0\n",
    "        metric = Dice(mode=\"binary\", zero_division=1).to(self.device)\n",
    "        f1_score = BinaryF1Score(multidim_average='global').to(self.device)\n",
    "        precision = BinaryPrecision(multidim_average='global').to(self.device)\n",
    "        recall = BinaryRecall(multidim_average='global').to(self.device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for X, y in dataloader:\n",
    "                X, y = X.to(device), y.to(device)\n",
    "                pred = model(X)\n",
    "                loss = self.loss_fn(pred, y.to(torch.float32)).item() # pred.squeeze(1)\n",
    "                test_loss += loss\n",
    "                dice = metric(pred, y.to(torch.int8))\n",
    "                loss_vals.append(loss)\n",
    "                test_dice += dice.item()\n",
    "                Dice_idx_vals.append(dice.item())\n",
    "                test_f1 += f1_score(pred, y.to(torch.int8)).item()\n",
    "                test_precision += precision(pred, y.to(torch.int8)).item()\n",
    "                test_recall += recall(pred, y.to(torch.int8)).item()\n",
    "\n",
    "        test_loss /= num_batches\n",
    "        test_dice /= num_batches\n",
    "        test_f1 /= num_batches\n",
    "        test_precision /= num_batches\n",
    "        test_recall /= num_batches\n",
    "        # correct /= size\n",
    "\n",
    "        # Dice_idx = 100 * metric(pred, y)\n",
    "        print(\n",
    "            f\"Test Error: \\n\"\n",
    "            f\"Dice-Coefficient: {test_dice:>0.2f}, Avg loss: {test_loss:>5f} \\n\"\n",
    "        )\n",
    "\n",
    "        return test_loss, loss_vals, test_dice, Dice_idx_vals, test_f1, test_precision, test_recall\n",
    "\n",
    "    def save_as_csv(self, data_dict: dict, filename: str) -> None:\n",
    "        df = pd.DataFrame.from_dict(data_dict)\n",
    "        df.to_csv(f\"{filename}.csv\", index=False)\n",
    "\n",
    "    def save_as_pickle(self, data_dict: dict, filename: str) -> None:\n",
    "        with open(f\"{filename}.pkl\", 'wb') as f:\n",
    "            pickle.dump(data_dict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = Path(r\"C:\\Users\\Fabian\\Documents\\Github_Masterthesis\\Solarpark-detection\\data_local\\data_splitted_undersampling_cleaned_verified\")\n",
    "\n",
    "train_images_path = Path(root / \"train/images\")\n",
    "train_masks_path = Path(root / \"train/masks\")\n",
    "val_images_path = Path(root / \"val/images\")\n",
    "val_masks_path = Path(root / \"val/masks\")\n",
    "test_images_path = Path(root / \"test/images\")\n",
    "test_masks_path = Path(root / \"test/masks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = None\n",
    "train_dataset = GeoImageDataset(train_images_path, train_masks_path, transform=transform)\n",
    "val_dataset = GeoImageDataset(val_images_path, val_masks_path, transform=transform)\n",
    "test_dataset = GeoImageDataset(test_images_path, test_masks_path, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "shuffle = True\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=shuffle)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=shuffle)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=shuffle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size train set: 11703\n",
      "Size val set: 3899\n",
      "Size test set: 1595\n"
     ]
    }
   ],
   "source": [
    "print(f\"Size train set: {train_dataset.__len__()}\")\n",
    "print(f\"Size val set: {val_dataset.__len__()}\")\n",
    "print(f\"Size test set: {test_dataset.__len__()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 0.605801  [   16/11703]\n",
      "loss: 0.340848  [  336/11703]\n",
      "loss: 0.202775  [  656/11703]\n",
      "loss: 0.118532  [  976/11703]\n",
      "loss: 0.096646  [ 1296/11703]\n",
      "loss: 0.069138  [ 1616/11703]\n",
      "loss: 0.048778  [ 1936/11703]\n",
      "loss: 0.051810  [ 2256/11703]\n",
      "loss: 0.031452  [ 2576/11703]\n",
      "loss: 0.034402  [ 2896/11703]\n",
      "loss: 0.036486  [ 3216/11703]\n",
      "loss: 0.028589  [ 3536/11703]\n",
      "loss: 0.026465  [ 3856/11703]\n",
      "loss: 0.023747  [ 4176/11703]\n",
      "loss: 0.020035  [ 4496/11703]\n",
      "loss: 0.015081  [ 4816/11703]\n",
      "loss: 0.039284  [ 5136/11703]\n",
      "loss: 0.014139  [ 5456/11703]\n",
      "loss: 0.022685  [ 5776/11703]\n",
      "loss: 0.012764  [ 6096/11703]\n",
      "loss: 0.018857  [ 6416/11703]\n",
      "loss: 0.012436  [ 6736/11703]\n",
      "loss: 0.010878  [ 7056/11703]\n",
      "loss: 0.015172  [ 7376/11703]\n",
      "loss: 0.016139  [ 7696/11703]\n",
      "loss: 0.035386  [ 8016/11703]\n",
      "loss: 0.013766  [ 8336/11703]\n",
      "loss: 0.008678  [ 8656/11703]\n",
      "loss: 0.010546  [ 8976/11703]\n",
      "loss: 0.008676  [ 9296/11703]\n",
      "loss: 0.008938  [ 9616/11703]\n",
      "loss: 0.010199  [ 9936/11703]\n",
      "loss: 0.016271  [10256/11703]\n",
      "loss: 0.005141  [10576/11703]\n",
      "loss: 0.004643  [10896/11703]\n",
      "loss: 0.011431  [11216/11703]\n",
      "loss: 0.005248  [11536/11703]\n",
      "Test Error: \n",
      "Dice-Coefficient: 0.64, Avg loss: 0.011765 \n",
      "\n",
      "Model saved!\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 0.010637  [   16/11703]\n",
      "loss: 0.017120  [  336/11703]\n",
      "loss: 0.007311  [  656/11703]\n",
      "loss: 0.017062  [  976/11703]\n",
      "loss: 0.004783  [ 1296/11703]\n",
      "loss: 0.005401  [ 1616/11703]\n",
      "loss: 0.004010  [ 1936/11703]\n",
      "loss: 0.004158  [ 2256/11703]\n",
      "loss: 0.008867  [ 2576/11703]\n",
      "loss: 0.004583  [ 2896/11703]\n",
      "loss: 0.004061  [ 3216/11703]\n",
      "loss: 0.008920  [ 3536/11703]\n",
      "loss: 0.003850  [ 3856/11703]\n",
      "loss: 0.008770  [ 4176/11703]\n",
      "loss: 0.009226  [ 4496/11703]\n",
      "loss: 0.010938  [ 4816/11703]\n",
      "loss: 0.006476  [ 5136/11703]\n",
      "loss: 0.009973  [ 5456/11703]\n",
      "loss: 0.006854  [ 5776/11703]\n",
      "loss: 0.003737  [ 6096/11703]\n",
      "loss: 0.011383  [ 6416/11703]\n",
      "loss: 0.009640  [ 6736/11703]\n",
      "loss: 0.006757  [ 7056/11703]\n",
      "loss: 0.004899  [ 7376/11703]\n",
      "loss: 0.004698  [ 7696/11703]\n",
      "loss: 0.006837  [ 8016/11703]\n",
      "loss: 0.006200  [ 8336/11703]\n",
      "loss: 0.006574  [ 8656/11703]\n",
      "loss: 0.003486  [ 8976/11703]\n",
      "loss: 0.015610  [ 9296/11703]\n",
      "loss: 0.008439  [ 9616/11703]\n",
      "loss: 0.002457  [ 9936/11703]\n",
      "loss: 0.007629  [10256/11703]\n",
      "loss: 0.002600  [10576/11703]\n",
      "loss: 0.004701  [10896/11703]\n",
      "loss: 0.005656  [11216/11703]\n",
      "loss: 0.007616  [11536/11703]\n",
      "Test Error: \n",
      "Dice-Coefficient: 0.67, Avg loss: 0.011001 \n",
      "\n",
      "Model saved!\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.005279  [   16/11703]\n",
      "loss: 0.002213  [  336/11703]\n",
      "loss: 0.003258  [  656/11703]\n",
      "loss: 0.003087  [  976/11703]\n",
      "loss: 0.002434  [ 1296/11703]\n",
      "loss: 0.007649  [ 1616/11703]\n",
      "loss: 0.002211  [ 1936/11703]\n",
      "loss: 0.003334  [ 2256/11703]\n",
      "loss: 0.006984  [ 2576/11703]\n",
      "loss: 0.006475  [ 2896/11703]\n",
      "loss: 0.007813  [ 3216/11703]\n",
      "loss: 0.018916  [ 3536/11703]\n",
      "loss: 0.004592  [ 3856/11703]\n",
      "loss: 0.003205  [ 4176/11703]\n",
      "loss: 0.006931  [ 4496/11703]\n",
      "loss: 0.004462  [ 4816/11703]\n",
      "loss: 0.001307  [ 5136/11703]\n",
      "loss: 0.015108  [ 5456/11703]\n",
      "loss: 0.004921  [ 5776/11703]\n",
      "loss: 0.009490  [ 6096/11703]\n",
      "loss: 0.002056  [ 6416/11703]\n",
      "loss: 0.008350  [ 6736/11703]\n",
      "loss: 0.002138  [ 7056/11703]\n",
      "loss: 0.002566  [ 7376/11703]\n",
      "loss: 0.003363  [ 7696/11703]\n",
      "loss: 0.009098  [ 8016/11703]\n",
      "loss: 0.001778  [ 8336/11703]\n",
      "loss: 0.002498  [ 8656/11703]\n",
      "loss: 0.004920  [ 8976/11703]\n",
      "loss: 0.004121  [ 9296/11703]\n",
      "loss: 0.002203  [ 9616/11703]\n",
      "loss: 0.005550  [ 9936/11703]\n",
      "loss: 0.002544  [10256/11703]\n",
      "loss: 0.001092  [10576/11703]\n",
      "loss: 0.012073  [10896/11703]\n",
      "loss: 0.006335  [11216/11703]\n",
      "loss: 0.008105  [11536/11703]\n",
      "Test Error: \n",
      "Dice-Coefficient: 0.72, Avg loss: 0.008229 \n",
      "\n",
      "Model saved!\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.001805  [   16/11703]\n",
      "loss: 0.003039  [  336/11703]\n",
      "loss: 0.005818  [  656/11703]\n",
      "loss: 0.011254  [  976/11703]\n",
      "loss: 0.001776  [ 1296/11703]\n",
      "loss: 0.006864  [ 1616/11703]\n",
      "loss: 0.004875  [ 1936/11703]\n",
      "loss: 0.016700  [ 2256/11703]\n",
      "loss: 0.009379  [ 2576/11703]\n",
      "loss: 0.010358  [ 2896/11703]\n",
      "loss: 0.002760  [ 3216/11703]\n",
      "loss: 0.005086  [ 3536/11703]\n",
      "loss: 0.002578  [ 3856/11703]\n",
      "loss: 0.003456  [ 4176/11703]\n",
      "loss: 0.008821  [ 4496/11703]\n",
      "loss: 0.010241  [ 4816/11703]\n",
      "loss: 0.004543  [ 5136/11703]\n",
      "loss: 0.005227  [ 5456/11703]\n",
      "loss: 0.003609  [ 5776/11703]\n",
      "loss: 0.007359  [ 6096/11703]\n",
      "loss: 0.003697  [ 6416/11703]\n",
      "loss: 0.007251  [ 6736/11703]\n",
      "loss: 0.003396  [ 7056/11703]\n",
      "loss: 0.001134  [ 7376/11703]\n",
      "loss: 0.002314  [ 7696/11703]\n",
      "loss: 0.003033  [ 8016/11703]\n",
      "loss: 0.008576  [ 8336/11703]\n",
      "loss: 0.004274  [ 8656/11703]\n",
      "loss: 0.003394  [ 8976/11703]\n",
      "loss: 0.003910  [ 9296/11703]\n",
      "loss: 0.000797  [ 9616/11703]\n",
      "loss: 0.006255  [ 9936/11703]\n",
      "loss: 0.003308  [10256/11703]\n",
      "loss: 0.002964  [10576/11703]\n",
      "loss: 0.004273  [10896/11703]\n",
      "loss: 0.004325  [11216/11703]\n",
      "loss: 0.001456  [11536/11703]\n",
      "Test Error: \n",
      "Dice-Coefficient: 0.73, Avg loss: 0.008162 \n",
      "\n",
      "Model saved!\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.002470  [   16/11703]\n",
      "loss: 0.002860  [  336/11703]\n",
      "loss: 0.005272  [  656/11703]\n",
      "loss: 0.003319  [  976/11703]\n",
      "loss: 0.005891  [ 1296/11703]\n",
      "loss: 0.005228  [ 1616/11703]\n",
      "loss: 0.001864  [ 1936/11703]\n",
      "loss: 0.003896  [ 2256/11703]\n",
      "loss: 0.006697  [ 2576/11703]\n",
      "loss: 0.002630  [ 2896/11703]\n",
      "loss: 0.017974  [ 3216/11703]\n",
      "loss: 0.001842  [ 3536/11703]\n",
      "loss: 0.003100  [ 3856/11703]\n",
      "loss: 0.001573  [ 4176/11703]\n",
      "loss: 0.005434  [ 4496/11703]\n",
      "loss: 0.001450  [ 4816/11703]\n",
      "loss: 0.008721  [ 5136/11703]\n",
      "loss: 0.004659  [ 5456/11703]\n",
      "loss: 0.006521  [ 5776/11703]\n",
      "loss: 0.000831  [ 6096/11703]\n",
      "loss: 0.002750  [ 6416/11703]\n",
      "loss: 0.003996  [ 6736/11703]\n",
      "loss: 0.004322  [ 7056/11703]\n",
      "loss: 0.003401  [ 7376/11703]\n",
      "loss: 0.003422  [ 7696/11703]\n",
      "loss: 0.004989  [ 8016/11703]\n",
      "loss: 0.011179  [ 8336/11703]\n",
      "loss: 0.004960  [ 8656/11703]\n",
      "loss: 0.010413  [ 8976/11703]\n",
      "loss: 0.008128  [ 9296/11703]\n",
      "loss: 0.001427  [ 9616/11703]\n",
      "loss: 0.001380  [ 9936/11703]\n",
      "loss: 0.004596  [10256/11703]\n",
      "loss: 0.001963  [10576/11703]\n",
      "loss: 0.001042  [10896/11703]\n",
      "loss: 0.002974  [11216/11703]\n",
      "loss: 0.009068  [11536/11703]\n",
      "Test Error: \n",
      "Dice-Coefficient: 0.69, Avg loss: 0.008799 \n",
      "\n",
      "Model timm-resnest14d trained and saved\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "loss_fn = nn.BCELoss()\n",
    "sampling = \"undersampling\"\n",
    "validated = \"cleaned_verified\"\n",
    "epochs = 5\n",
    "transform = \"None\"\n",
    "max_lr = 0.01\n",
    "\n",
    "for backbone in [\"timm-resnest14d\"]:\n",
    "    model = smp.Unet(\n",
    "        encoder_name=backbone,\n",
    "        encoder_weights='imagenet',\n",
    "        in_channels=4,\n",
    "        classes=1,\n",
    "        activation='sigmoid',\n",
    "    ).to(device)\n",
    "    trainer = Trainer(loss_fn, max_lr=max_lr, epochs=epochs, transform=transform)\n",
    "    trainer.train_and_save(model, train_dataloader, val_dataloader, sampling, validated, backbone, batch_size)\n",
    "    print(f\"Model {backbone} trained and saved\")\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
